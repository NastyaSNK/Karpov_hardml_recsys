{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67984e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расскоментируйте код ниже, чтобы установить все зависимости\n",
    "!pip install -q \\\n",
    "    pyarrow==12.0.1 \\\n",
    "    polars==0.18.6 \\\n",
    "    tqdm==4.65.0 \\\n",
    "    scipy==1.10.1 \\\n",
    "    scikit-learn==1.3.0 \\\n",
    "    numpy==1.24.3 \\\n",
    "    qdrant-client==1.3.1 \\\n",
    "    faiss-cpu==1.7.4 \\\n",
    "    redis==4.6.0 \\\n",
    "    implicit==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e95fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# раскоментируйте код ниже, чтобы скачать данные\n",
    "!wget -q https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -q ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48c874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import redis\n",
    "import faiss\n",
    "import implicit\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from typing import List, Any\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16160e2d",
   "metadata": {},
   "source": [
    "## MovieLens датасет\n",
    "\n",
    "В качестве данных будем использовать датасет с оценками к фильмам Movielens-100k. В нем есть поле ratings, в качестве позитивных событий мы будем считать то, что пользователь поставил оценку > 3 (такое правило принято в статьях, работающих с этим датасетом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b843a01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (55_375, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th><th>timestamp</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>298</td><td>474</td><td>4</td><td>884182806</td></tr><tr><td>253</td><td>465</td><td>5</td><td>891628467</td></tr><tr><td>286</td><td>1014</td><td>5</td><td>879781125</td></tr><tr><td>200</td><td>222</td><td>5</td><td>876042340</td></tr><tr><td>122</td><td>387</td><td>5</td><td>879270459</td></tr><tr><td>291</td><td>1042</td><td>4</td><td>874834944</td></tr><tr><td>119</td><td>392</td><td>4</td><td>886176814</td></tr><tr><td>167</td><td>486</td><td>4</td><td>892738452</td></tr><tr><td>299</td><td>144</td><td>4</td><td>877881320</td></tr><tr><td>308</td><td>1</td><td>4</td><td>887736532</td></tr><tr><td>38</td><td>95</td><td>5</td><td>892430094</td></tr><tr><td>63</td><td>277</td><td>4</td><td>875747401</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>429</td><td>199</td><td>5</td><td>882386006</td></tr><tr><td>897</td><td>369</td><td>4</td><td>879993713</td></tr><tr><td>936</td><td>287</td><td>4</td><td>886832419</td></tr><tr><td>821</td><td>151</td><td>4</td><td>874792889</td></tr><tr><td>113</td><td>975</td><td>5</td><td>875936424</td></tr><tr><td>864</td><td>685</td><td>4</td><td>888891900</td></tr><tr><td>617</td><td>582</td><td>4</td><td>883789294</td></tr><tr><td>421</td><td>498</td><td>4</td><td>892241344</td></tr><tr><td>495</td><td>1091</td><td>4</td><td>888637503</td></tr><tr><td>806</td><td>421</td><td>4</td><td>882388897</td></tr><tr><td>676</td><td>538</td><td>4</td><td>892685437</td></tr><tr><td>716</td><td>204</td><td>5</td><td>879795543</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (55_375, 4)\n",
       "┌─────────┬─────────┬────────┬───────────┐\n",
       "│ user_id ┆ item_id ┆ rating ┆ timestamp │\n",
       "│ ---     ┆ ---     ┆ ---    ┆ ---       │\n",
       "│ i64     ┆ i64     ┆ i64    ┆ i64       │\n",
       "╞═════════╪═════════╪════════╪═══════════╡\n",
       "│ 298     ┆ 474     ┆ 4      ┆ 884182806 │\n",
       "│ 253     ┆ 465     ┆ 5      ┆ 891628467 │\n",
       "│ 286     ┆ 1014    ┆ 5      ┆ 879781125 │\n",
       "│ 200     ┆ 222     ┆ 5      ┆ 876042340 │\n",
       "│ …       ┆ …       ┆ …      ┆ …         │\n",
       "│ 495     ┆ 1091    ┆ 4      ┆ 888637503 │\n",
       "│ 806     ┆ 421     ┆ 4      ┆ 882388897 │\n",
       "│ 676     ┆ 538     ┆ 4      ┆ 892685437 │\n",
       "│ 716     ┆ 204     ┆ 5      ┆ 879795543 │\n",
       "└─────────┴─────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pl.read_csv(\n",
    "    'ml-100k/u.data',\n",
    "    separator='\\t',\n",
    "    has_header=False,\n",
    "    new_columns=['user_id', 'item_id', 'rating', 'timestamp']\n",
    ")\n",
    "# в качестве позитивной реакции возьмем оценки больше 3\n",
    "ratings = ratings.filter(pl.col('rating') > 3)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7efaf213-9e72-4ead-9335-7644bb6f9143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>rating</th><th>counts</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>4</td><td>34174</td></tr><tr><td>5</td><td>21201</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────┬────────┐\n",
       "│ rating ┆ counts │\n",
       "│ ---    ┆ ---    │\n",
       "│ i64    ┆ u32    │\n",
       "╞════════╪════════╡\n",
       "│ 4      ┆ 34174  │\n",
       "│ 5      ┆ 21201  │\n",
       "└────────┴────────┘"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a939b47-c1eb-437a-b87d-1ca577ca704b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 1447)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['user_id'].n_unique(), ratings['item_id'].n_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77812903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# возьмем последние 5% по времени в качестве отложенной выборки\n",
    "# все что до этого момента, будем использовать для обучения модели\n",
    "ts_threshold = ratings['timestamp'].quantile(0.95)\n",
    "holdout_set = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "ratings = ratings.filter(pl.col('timestamp') < ts_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76842b57-83dc-455c-902c-90fa6881031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(911, 1415)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['user_id'].n_unique(), ratings['item_id'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7f3a9-a4a0-4482-a21e-6451f49f3ac1",
   "metadata": {},
   "source": [
    "не все объекты и пользователи попали в датасет для обучения модели коллаборативной фильтрации. Значит будет проблема холодных пользователей и объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92171b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TOP_K = 10\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    random.seed(RANDOM_STATE)\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "def fit_als(ratings: pl.DataFrame, als_params={\"factors\": 64}):\n",
    "    \"\"\"Метод обучает модель ALS и возвращает эмбеддинги пользователей и объектов\n",
    "    Про ALS мы поговорим в следующем уроке, а пока что воспользуемся реализацией из библиотеки implicit\n",
    "\n",
    "    :param ratings: датафрейм с рейтингами\n",
    "    :param als_params: параметры для обучения модели ALS\n",
    "    :return: (user_embeddings, item_embeddings)\n",
    "    \"\"\"\n",
    "    set_seed()\n",
    "\n",
    "    # соберем разреженную матрицу рейтингов\n",
    "    rows = ratings[\"user_id\"].to_numpy()\n",
    "    cols = ratings[\"item_id\"].to_numpy()\n",
    "    values = ratings[\"rating\"].to_numpy() if \"rating\" in ratings else np.ones_like(rows)\n",
    "    user_item_data = sp.csr_matrix((values, (rows, cols)))\n",
    "\n",
    "    # обучим модель ALS\n",
    "    als_params.setdefault(\"random_state\", RANDOM_STATE)\n",
    "    # если есть gpu, используем его для ускорения\n",
    "    als_params.setdefault(\"use_gpu\", implicit.gpu.HAS_CUDA)\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(**als_params)\n",
    "    model.fit(user_item_data)\n",
    "\n",
    "    if als_params['use_gpu']:\n",
    "        return model.user_factors.to_numpy(), model.item_factors.to_numpy()\n",
    "\n",
    "    return model.user_factors, model.item_factors\n",
    "\n",
    "\n",
    "def get_recommendations(user_embs: np.array, item_embs: np.array, k: int = TOP_K):\n",
    "    # строим индекс объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    # строим рекомендации с помощью dot-product расстояния\n",
    "    # с запасом, чтобы после фильтрации просмотренных осталось как минимум TOP_K\n",
    "    return index.search(user_embs, TOP_K * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554afec",
   "metadata": {},
   "source": [
    "## Метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f354b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_hitrate(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    :param y_rel: релевантные объекты\n",
    "    :param y_rec: рекомендованные объекты\n",
    "    :param k: число рекомендации для показа (top-K результаты)\n",
    "    :return: 1, если top-k рекомендации содержат как минимум один релевантный объект\n",
    "    \"\"\"\n",
    "    return int(len(set(y_rec[:k]).intersection(set(y_rel))) > 0)\n",
    "\n",
    "\n",
    "# метод для оценки качества на отложенной выборке\n",
    "# можно сначала посмотреть следующие ячейки, чтобы понять, что тут происходит\n",
    "def evaluate_holdout_set(\n",
    "    train_df: pl.DataFrame, user_embs: np.array, item_embs: np.array, k: int = TOP_K\n",
    "):\n",
    "    # строим индекс эмбеддингов объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    hitrate_list = []\n",
    "    hitrate_list_by_type = {\"warm\": [], \"cold\": []}\n",
    "\n",
    "    # датафрейм с колонками user_id, train_item_ids, test_item_ids\n",
    "    # нам интересно провалидировать только по тем пользователям, которые есть в отложенной выборке\n",
    "    # поэтому train_item_ids может быть пустым\n",
    "    grouped_user_items = (\n",
    "        holdout_set.groupby(\"user_id\")\n",
    "        .agg(pl.col(\"item_id\").alias(\"test_item_ids\"))\n",
    "        .join(\n",
    "            train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n",
    "            \"user_id\",\n",
    "            \"left\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # предподсчитаем рекомендации по эмбеддингам пользователей и объектов (только для warm пользователей)\n",
    "    _, recs = get_recommendations(user_embs, item_embs)\n",
    "\n",
    "    for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "        if train_ids:\n",
    "            # если есть история для пользователя, то используем предподсчитанные рекомендации\n",
    "            user_history = train_ids\n",
    "\n",
    "            y_rel = test_ids\n",
    "            y_rec = [\n",
    "                item_id for item_id in recs[user_id] if item_id not in user_history\n",
    "            ]\n",
    "            hitrate_list_by_type[\"warm\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "        else:\n",
    "            # если нет истории пользователя, то используем сумму эмбеддингов объектов\n",
    "            user_emb = np.zeros(item_embs.shape[1])\n",
    "            user_history = set()\n",
    "            h_r = []\n",
    "            for i, item_ind in enumerate(test_ids[:-1]):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                user_history.add(item_ind)\n",
    "                \n",
    "                # хотим порекомендовать следующий объект\n",
    "                y_rel = [test_ids[i + 1]]\n",
    "                y_rec = [\n",
    "                    item_id\n",
    "                    for item_id in index.search(user_emb[np.newaxis, :], k + 1)[1][0]\n",
    "                    if item_id not in user_history\n",
    "                ]\n",
    "                hitrate_list_by_type[\"cold\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "            \n",
    "    all_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"] + hitrate_list_by_type[\"cold\"])\n",
    "    warm_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"]) if hitrate_list_by_type[\"warm\"] else 1.0\n",
    "    cold_users_hitrate = np.mean(hitrate_list_by_type[\"cold\"]) if hitrate_list_by_type[\"cold\"] else 1.0\n",
    "    return {\n",
    "        \"all\": all_users_hitrate,\n",
    "        \"warm\": warm_users_hitrate,\n",
    "        \"cold\": cold_users_hitrate,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "098a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 3) == 1\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 2) == 0\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 6], 10) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e3c7b",
   "metadata": {},
   "source": [
    "## Случайная вадидация\n",
    "\n",
    "Можно сказать, что в валидацию попадает какой-то процент взаимодействий, а в тренировочную выборку все остальное. С точки зрения реализации самый простой способ, однако совсем никак не контролирует дата-лики, когда информация из будущего оказывается в прошлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1709332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    ratings,\n",
    "    # будем сэмплировать так, чтобы пользователи встречались с той же вероятностью\n",
    "    stratify=ratings['user_id'],\n",
    "    test_size=TEST_SIZE,\n",
    "    # зафиксируем генератор случайных чисел для воспроизводимости результатов\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b19ceacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94a51848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (904, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>98</td><td>[25]</td><td>[435, 517, … 523]</td></tr><tr><td>230</td><td>[204, 117, … 125]</td><td>[132, 69, … 549]</td></tr><tr><td>290</td><td>[22, 143, … 222]</td><td>[183, 164, … 472]</td></tr><tr><td>48</td><td>[170, 132, … 50]</td><td>[483, 479, … 511]</td></tr><tr><td>150</td><td>[288, 246, 410]</td><td>[235, 268, … 291]</td></tr><tr><td>858</td><td>[689]</td><td>[9, 127, … 754]</td></tr><tr><td>310</td><td>[845]</td><td>[304, 24, … 50]</td></tr><tr><td>620</td><td>[379, 281, … 404]</td><td>[1503, 699, … 623]</td></tr><tr><td>854</td><td>[238, 979, … 606]</td><td>[507, 250, … 9]</td></tr><tr><td>236</td><td>[328, 596, … 546]</td><td>[420, 69, … 692]</td></tr><tr><td>598</td><td>[313]</td><td>[312, 22, … 292]</td></tr><tr><td>470</td><td>[475, 93, 118]</td><td>[283, 276, … 824]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>731</td><td>[945, 705, … 197]</td><td>[427, 170, … 393]</td></tr><tr><td>915</td><td>[302]</td><td>[268, 347, … 345]</td></tr><tr><td>191</td><td>[301]</td><td>[302, 345, … 331]</td></tr><tr><td>383</td><td>[514, 193, … 478]</td><td>[1063, 135, … 464]</td></tr><tr><td>199</td><td>[9, 313]</td><td>[7, 286, … 473]</td></tr><tr><td>635</td><td>[262]</td><td>[1, 302, … 331]</td></tr><tr><td>183</td><td>[405]</td><td>[649, 55, … 228]</td></tr><tr><td>531</td><td>[312, 1316]</td><td>[329, 300, … 313]</td></tr><tr><td>7</td><td>[550, 596, … 527]</td><td>[237, 648, … 660]</td></tr><tr><td>935</td><td>[284, 864, 127]</td><td>[181, 117, … 300]</td></tr><tr><td>5</td><td>[109, 204, … 455]</td><td>[257, 432, … 40]</td></tr><tr><td>525</td><td>[596, 282]</td><td>[1, 405, … 15]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (904, 3)\n",
       "┌─────────┬───────────────────┬───────────────────┐\n",
       "│ user_id ┆ test_item_ids     ┆ train_item_ids    │\n",
       "│ ---     ┆ ---               ┆ ---               │\n",
       "│ i64     ┆ list[i64]         ┆ list[i64]         │\n",
       "╞═════════╪═══════════════════╪═══════════════════╡\n",
       "│ 98      ┆ [25]              ┆ [435, 517, … 523] │\n",
       "│ 230     ┆ [204, 117, … 125] ┆ [132, 69, … 549]  │\n",
       "│ 290     ┆ [22, 143, … 222]  ┆ [183, 164, … 472] │\n",
       "│ 48      ┆ [170, 132, … 50]  ┆ [483, 479, … 511] │\n",
       "│ …       ┆ …                 ┆ …                 │\n",
       "│ 7       ┆ [550, 596, … 527] ┆ [237, 648, … 660] │\n",
       "│ 935     ┆ [284, 864, 127]   ┆ [181, 117, … 300] │\n",
       "│ 5       ┆ [109, 204, … 455] ┆ [257, 432, … 40]  │\n",
       "│ 525     ┆ [596, 282]        ┆ [1, 405, … 15]    │\n",
       "└─────────┴───────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгруппируем в список индексов объекты из тренировочной выборки и валидационной\n",
    "train_user_items = train_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"train_item_ids\")\n",
    ")\n",
    "test_user_items = test_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"test_item_ids\")\n",
    ")\n",
    "# объединим все в одну табличку, при этом важно оставить всех тех\n",
    "# пользователей, которые есть в валидационной выборке\n",
    "grouped_user_items = test_user_items.join(train_user_items, \"user_id\", \"left\")\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "701c67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 1.0\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    # строим рекомендации из тех объектов, которые уже не были в тренировочной выборке\n",
    "    y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5de03b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.06108597285067873,\n",
       " 'warm': 0.21739130434782608,\n",
       " 'cold': 0.05473808122424956}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca18a0d",
   "metadata": {},
   "source": [
    "На валидации получили идеальную метрику hitrate, однако на отложенной выборке самый худший результат по сравнению со следующими методами валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c0b1a",
   "metadata": {},
   "source": [
    "## Валидация по пользователям\n",
    "\n",
    "Здесь мы делаем разделение данных уже по полю user_id, то есть какие-то пользователи попадут только в тестовую выборку и с точки зрения алгоритма будут холодными (cold) пользователями\n",
    "\n",
    "Для того, чтобы построить рекомендации для таких пользователей, будем использовать эмбеддинги объектов в реальном времени. То есть если для валидации у нас есть список объектов [item_1, item_2, item_3, ...], то для первого объекта ничего не рекомендуем (или еще лучше рекомендовать популярные объекты). В момент рекомендации второго объекта у нас есть история для пользователя: [item_1], тогда эмбединг пользователя равен эмбеддингу item_1. Для следующего объекта эмбеддинг будет равен сумме эмбеддингов item_1 и item_2 и так далее.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87b1b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем генератор случайных чисел для воспроизводимости\n",
    "np.random.seed(RANDOM_STATE)  \n",
    "\n",
    "# выберем среди всех пользователей тех, кто будет в тренировочной выборке, а кто в тестовой\n",
    "unique_users = ratings[\"user_id\"].unique().to_list()\n",
    "test_users = set(\n",
    "    np.random.choice(unique_users, int(len(unique_users) * TEST_SIZE), replace=False)\n",
    ")\n",
    "train_users = set(unique_users).difference(test_users)\n",
    "\n",
    "train_df = ratings.filter(pl.col(\"user_id\").is_in(train_users))\n",
    "test_df = ratings.filter(pl.col(\"user_id\").is_in(test_users))\n",
    "\n",
    "# sanity check\n",
    "assert set(train_df[\"user_id\"].unique().to_list()) == train_users\n",
    "assert set(test_df[\"user_id\"].unique().to_list()) == test_users\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "076b344c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5bfe1c31-d4f4-4775-aabd-0baf47b45d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (91, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>572</td><td>[300, 476, … 813]</td><td>null</td></tr><tr><td>76</td><td>[61, 175, … 96]</td><td>null</td></tr><tr><td>66</td><td>[298, 258, … 300]</td><td>null</td></tr><tr><td>78</td><td>[255, 412, … 411]</td><td>null</td></tr><tr><td>748</td><td>[748, 22, … 199]</td><td>null</td></tr><tr><td>26</td><td>[125, 15, … 288]</td><td>null</td></tr><tr><td>148</td><td>[408, 1, … 194]</td><td>null</td></tr><tr><td>34</td><td>[312, 242, … 991]</td><td>null</td></tr><tr><td>318</td><td>[474, 356, … 340]</td><td>null</td></tr><tr><td>146</td><td>[1022, 262, … 311]</td><td>null</td></tr><tr><td>224</td><td>[77, 69, … 731]</td><td>null</td></tr><tr><td>92</td><td>[172, 168, … 65]</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>219</td><td>[179, 303, … 433]</td><td>null</td></tr><tr><td>681</td><td>[898, 539, … 292]</td><td>null</td></tr><tr><td>319</td><td>[313, 879, … 301]</td><td>null</td></tr><tr><td>815</td><td>[196, 173, … 526]</td><td>null</td></tr><tr><td>783</td><td>[346, 876, … 895]</td><td>null</td></tr><tr><td>563</td><td>[1035, 692, … 566]</td><td>null</td></tr><tr><td>501</td><td>[307, 324, … 150]</td><td>null</td></tr><tr><td>923</td><td>[333, 237, … 411]</td><td>null</td></tr><tr><td>559</td><td>[902, 188, … 652]</td><td>null</td></tr><tr><td>375</td><td>[356, 684, … 234]</td><td>null</td></tr><tr><td>455</td><td>[135, 293, … 164]</td><td>null</td></tr><tr><td>73</td><td>[480, 657, … 514]</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (91, 3)\n",
       "┌─────────┬───────────────────┬────────────────┐\n",
       "│ user_id ┆ test_item_ids     ┆ train_item_ids │\n",
       "│ ---     ┆ ---               ┆ ---            │\n",
       "│ i64     ┆ list[i64]         ┆ list[i64]      │\n",
       "╞═════════╪═══════════════════╪════════════════╡\n",
       "│ 572     ┆ [300, 476, … 813] ┆ null           │\n",
       "│ 76      ┆ [61, 175, … 96]   ┆ null           │\n",
       "│ 66      ┆ [298, 258, … 300] ┆ null           │\n",
       "│ 78      ┆ [255, 412, … 411] ┆ null           │\n",
       "│ …       ┆ …                 ┆ …              │\n",
       "│ 559     ┆ [902, 188, … 652] ┆ null           │\n",
       "│ 375     ┆ [356, 684, … 234] ┆ null           │\n",
       "│ 455     ┆ [135, 293, … 164] ┆ null           │\n",
       "│ 73      ┆ [480, 657, … 514] ┆ null           │\n",
       "└─────────┴───────────────────┴────────────────┘"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгруппируем в список индексов объекты из тренировочной выборки и валидационной\n",
    "train_user_items = train_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"train_item_ids\")\n",
    ")\n",
    "test_user_items = test_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"test_item_ids\")\n",
    ")\n",
    "# объединим все в одну табличку, при этом важно оставить всех тех\n",
    "# пользователей, которые есть в валидационной выборке\n",
    "grouped_user_items = test_user_items.join(train_user_items, \"user_id\", \"left\")\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72030097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.11200508151598561\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "hitrate_list = []\n",
    "for _, user_session, _ in grouped_user_items.rows():\n",
    "    user_emb = np.zeros(item_embs.shape[1])\n",
    "    user_history = set()\n",
    "    # эмбеддинг пользователя - сумма эмбеддингов позитивных объектов\n",
    "    # пройдемся по каждому объекту и постараемся предсказать следующие в сессии\n",
    "    for i, item_ind in enumerate(user_session[:-1]):\n",
    "        user_emb += item_embs[item_ind]\n",
    "        user_history.add(item_ind)\n",
    "        \n",
    "        y_rel = [user_session[i + 1]]\n",
    "        y_rec = [\n",
    "            item_id \n",
    "            for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "            if item_id not in user_history\n",
    "        ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dd292f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.06195175438596491,\n",
       " 'warm': 0.27419354838709675,\n",
       " 'cold': 0.05448354143019296}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a71c9",
   "metadata": {},
   "source": [
    "## Валидация по времени\n",
    "\n",
    "Такая валидация дублирует реально поведение системы, когда у нас есть данные только из прошлого и мы хотим порекомендовать для будущего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32c38de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_threshold = ratings['timestamp'].quantile(1 - TEST_SIZE)\n",
    "train_df = ratings.filter(pl.col('timestamp') < ts_threshold)\n",
    "test_df = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "37e7c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd3644c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (126, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>642</td><td>[845, 993, 245]</td><td>[1039, 38, … 73]</td></tr><tr><td>358</td><td>[469, 896, … 1005]</td><td>null</td></tr><tr><td>938</td><td>[864, 313, … 993]</td><td>null</td></tr><tr><td>942</td><td>[117, 200, … 259]</td><td>null</td></tr><tr><td>922</td><td>[143, 89, … 596]</td><td>null</td></tr><tr><td>574</td><td>[300, 258, … 754]</td><td>null</td></tr><tr><td>842</td><td>[268, 269, … 333]</td><td>null</td></tr><tr><td>532</td><td>[269]</td><td>[58, 70, … 425]</td></tr><tr><td>332</td><td>[350]</td><td>[566, 693, … 550]</td></tr><tr><td>252</td><td>[277, 300, … 124]</td><td>null</td></tr><tr><td>720</td><td>[258, 304, … 242]</td><td>null</td></tr><tr><td>816</td><td>[309, 343, … 690]</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>121</td><td>[14, 509, … 292]</td><td>null</td></tr><tr><td>753</td><td>[79, 898, … 193]</td><td>null</td></tr><tr><td>91</td><td>[480, 28, … 79]</td><td>null</td></tr><tr><td>423</td><td>[744, 237, … 508]</td><td>null</td></tr><tr><td>27</td><td>[298, 121, … 123]</td><td>null</td></tr><tr><td>547</td><td>[328, 316, … 751]</td><td>null</td></tr><tr><td>253</td><td>[465, 97, … 318]</td><td>null</td></tr><tr><td>445</td><td>[1591, 475, … 151]</td><td>[28, 340, … 96]</td></tr><tr><td>107</td><td>[305, 258, … 312]</td><td>null</td></tr><tr><td>169</td><td>[301, 174, … 606]</td><td>null</td></tr><tr><td>215</td><td>[211, 421, … 54]</td><td>null</td></tr><tr><td>111</td><td>[328, 301, … 304]</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (126, 3)\n",
       "┌─────────┬────────────────────┬──────────────────┐\n",
       "│ user_id ┆ test_item_ids      ┆ train_item_ids   │\n",
       "│ ---     ┆ ---                ┆ ---              │\n",
       "│ i64     ┆ list[i64]          ┆ list[i64]        │\n",
       "╞═════════╪════════════════════╪══════════════════╡\n",
       "│ 642     ┆ [845, 993, 245]    ┆ [1039, 38, … 73] │\n",
       "│ 358     ┆ [469, 896, … 1005] ┆ null             │\n",
       "│ 938     ┆ [864, 313, … 993]  ┆ null             │\n",
       "│ 942     ┆ [117, 200, … 259]  ┆ null             │\n",
       "│ …       ┆ …                  ┆ …                │\n",
       "│ 107     ┆ [305, 258, … 312]  ┆ null             │\n",
       "│ 169     ┆ [301, 174, … 606]  ┆ null             │\n",
       "│ 215     ┆ [211, 421, … 54]   ┆ null             │\n",
       "│ 111     ┆ [328, 301, … 304]  ┆ null             │\n",
       "└─────────┴────────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_items = train_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('train_item_ids')\n",
    ")\n",
    "test_user_items = test_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('test_item_ids')\n",
    ")\n",
    "grouped_user_items = test_user_items.join(train_user_items, 'user_id', 'left')\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ffa80a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.1154877294287482\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "    if train_ids:\n",
    "        # используем инференс модели с помощью эмбеддинга пользователя\n",
    "        user_history = train_ids\n",
    "        \n",
    "        y_rel = test_ids\n",
    "        y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "    else:\n",
    "        # используем итеративный эмбеддинг по объектам\n",
    "        user_emb = np.zeros(item_embs.shape[1])\n",
    "        user_history = set()\n",
    "        for i, item_ind in enumerate(test_ids[:-1]):\n",
    "            if item_ind < len(item_embs):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                \n",
    "            user_history.add(item_ind)    \n",
    "            y_rel = [test_ids[i + 1]]\n",
    "            y_rec = [\n",
    "                item_id \n",
    "                for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "                if item_id not in user_history\n",
    "            ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83a1a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.060228452751817235,\n",
       " 'warm': 0.20689655172413793,\n",
       " 'cold': 0.055674518201284794}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba7267",
   "metadata": {},
   "source": [
    "## Валидация по событиям\n",
    "\n",
    "В такой валидации мы рассматриваем для пользователя все взаимодействия, отсортированные по времени и оставляем последние N взаимодействия в качестве валидации, а все что раньше – для тренировки. У этого способа есть такая же проблема с тем, что при обучении могут сказываться дата-лики, однако в этом случае мы учитываем как холодных, так и теплых пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "81b23fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (911, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>train_item_ids</th><th>test_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>174</td><td>[315, 268, … 709]</td><td>[238]</td></tr><tr><td>298</td><td>[286, 172, … 252]</td><td>[820]</td></tr><tr><td>760</td><td>[258, 288, … 1135]</td><td>[375]</td></tr><tr><td>900</td><td>[294, 237, … 483]</td><td>[618]</td></tr><tr><td>624</td><td>[258, 286, … 272]</td><td>[313]</td></tr><tr><td>426</td><td>[332, 492, … 505]</td><td>[185]</td></tr><tr><td>822</td><td>[333, 902, … 71]</td><td>[111]</td></tr><tr><td>108</td><td>[294, 319, … 281]</td><td>[290]</td></tr><tr><td>480</td><td>[272, 302, … 642]</td><td>[504]</td></tr><tr><td>628</td><td>[270, 302, … 258]</td><td>[294]</td></tr><tr><td>190</td><td>[326, 245, … 628]</td><td>[405]</td></tr><tr><td>356</td><td>[315, 347, … 316]</td><td>[748]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>17</td><td>[269, 294, … 126]</td><td>[151]</td></tr><tr><td>771</td><td>[690, 242, … 304]</td><td>[892]</td></tr><tr><td>601</td><td>[258, 324, … 431]</td><td>[382]</td></tr><tr><td>717</td><td>[302, 340, … 246]</td><td>[127]</td></tr><tr><td>885</td><td>[300, 538, … 419]</td><td>[143]</td></tr><tr><td>465</td><td>[286, 258, … 202]</td><td>[318]</td></tr><tr><td>877</td><td>[270, 269, … 566]</td><td>[164]</td></tr><tr><td>607</td><td>[487, 100, … 56]</td><td>[30]</td></tr><tr><td>261</td><td>[340, 288, … 410]</td><td>[125]</td></tr><tr><td>897</td><td>[288, 323, … 232]</td><td>[646]</td></tr><tr><td>187</td><td>[300, 137, … 275]</td><td>[462]</td></tr><tr><td>95</td><td>[151, 683, … 1116]</td><td>[445]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (911, 3)\n",
       "┌─────────┬────────────────────┬───────────────┐\n",
       "│ user_id ┆ train_item_ids     ┆ test_item_ids │\n",
       "│ ---     ┆ ---                ┆ ---           │\n",
       "│ i64     ┆ list[i64]          ┆ list[i64]     │\n",
       "╞═════════╪════════════════════╪═══════════════╡\n",
       "│ 174     ┆ [315, 268, … 709]  ┆ [238]         │\n",
       "│ 298     ┆ [286, 172, … 252]  ┆ [820]         │\n",
       "│ 760     ┆ [258, 288, … 1135] ┆ [375]         │\n",
       "│ 900     ┆ [294, 237, … 483]  ┆ [618]         │\n",
       "│ …       ┆ …                  ┆ …             │\n",
       "│ 261     ┆ [340, 288, … 410]  ┆ [125]         │\n",
       "│ 897     ┆ [288, 323, … 232]  ┆ [646]         │\n",
       "│ 187     ┆ [300, 137, … 275]  ┆ [462]         │\n",
       "│ 95      ┆ [151, 683, … 1116] ┆ [445]         │\n",
       "└─────────┴────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_user_items = (\n",
    "    ratings\n",
    "    .sort('timestamp')\n",
    "    .groupby('user_id')\n",
    "    .agg([\n",
    "        pl.col('item_id').apply(lambda x: x[:-1]).alias('train_item_ids'),\n",
    "        pl.col('item_id').apply(lambda x: [x[-1]]).alias('test_item_ids')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# sanity check\n",
    "assert len(\n",
    "    grouped_user_items\n",
    "    .filter(pl.col('test_item_ids').apply(lambda x: len(x) == 0))\n",
    ") == 0\n",
    "\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bfa4b783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = (\n",
    "    grouped_user_items\n",
    "    .select('user_id', 'train_item_ids')\n",
    "    .explode('train_item_ids')\n",
    "    .rename({'train_item_ids': 'item_id'})\n",
    ")\n",
    "\n",
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "86e96425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.09330406147091108\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    y_rec = [\n",
    "        item_id\n",
    "        for item_id in recs[user_id]\n",
    "        if item_id not in user_history\n",
    "    ]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2794ee74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.07352941176470588,\n",
       " 'warm': 0.2318840579710145,\n",
       " 'cold': 0.06709829311359623}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcf2e9",
   "metadata": {},
   "source": [
    "## Approximate KNN с помощью Qdrant\n",
    "\n",
    "В отдельном процессе нужно запустить серверную часть [qdrant](https://qdrant.tech/) следующей командой:\n",
    "\n",
    "`docker run -p 6333:6333 qdrant/qdrant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a6394cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"item_embs\",\n",
    "    # задаем размерность векторов и метрику дистанции\n",
    "    vectors_config=VectorParams(size=item_embs.shape[1], distance=Distance.DOT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84ae462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation_info = client.upsert(\n",
    "    collection_name=\"item_embs\",\n",
    "    wait=True,\n",
    "    points=[\n",
    "        PointStruct(id=(item_id + 1), vector=item_emb.tolist())\n",
    "        for item_id, item_emb in enumerate(item_embs[1:])\n",
    "    ]\n",
    ")\n",
    "operation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d4c9326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=222, version=0, score=0.33572915, payload={}, vector=None),\n",
       " ScoredPoint(id=228, version=0, score=0.31374466, payload={}, vector=None),\n",
       " ScoredPoint(id=202, version=0, score=0.30496037, payload={}, vector=None),\n",
       " ScoredPoint(id=227, version=0, score=0.28887057, payload={}, vector=None),\n",
       " ScoredPoint(id=405, version=0, score=0.2654244, payload={}, vector=None),\n",
       " ScoredPoint(id=230, version=0, score=0.23762143, payload={}, vector=None),\n",
       " ScoredPoint(id=229, version=0, score=0.18529022, payload={}, vector=None),\n",
       " ScoredPoint(id=196, version=0, score=0.18061997, payload={}, vector=None),\n",
       " ScoredPoint(id=380, version=0, score=0.17917344, payload={}, vector=None),\n",
       " ScoredPoint(id=151, version=0, score=0.16398694, payload={}, vector=None)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 183\n",
    "search_result = client.search(\n",
    "    collection_name=\"item_embs\",\n",
    "    query_vector=user_embs[user_id].tolist(),\n",
    "    limit=TOP_K\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5af269c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rel = holdout_set.filter(pl.col('user_id') == user_id)['item_id'].to_list()\n",
    "y_rec = [s.id for s in search_result]\n",
    "user_hitrate(y_rel, y_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cc743",
   "metadata": {},
   "source": [
    "## watched filter с разреженной матрицей\n",
    "\n",
    "Для работы с redis нужно запустить docker контейнер следующей командой:\n",
    "\n",
    "`docker run --rm -p 6379:6379 redis/redis-stack-server:latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7887ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "n_interactions = 10_000\n",
    "n_users = 10_000\n",
    "n_items = 1_000_000\n",
    "\n",
    "# wanna generate sparse matrix\n",
    "assert n_interactions <= n_users * n_items / 100\n",
    "\n",
    "interactions = set()\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    while True:\n",
    "        user = np.random.choice(n_users)\n",
    "        item = np.random.choice(n_items)\n",
    "\n",
    "        if (item, user) not in interactions:\n",
    "            interactions.add((item, user))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03b2ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='localhost', db=0)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d321b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, user in interactions:\n",
    "    r.set(f'{item}-{user}', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdd76a",
   "metadata": {},
   "source": [
    "Использовали ~500Кб памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e39a79cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4972 ± 0.3755 ms\n"
     ]
    }
   ],
   "source": [
    "for item, user in interactions:\n",
    "    assert r.get(f'{item}-{user}') is not None\n",
    "    \n",
    "get_time_elapsed = []\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.get(f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions:\n",
    "        assert get_result is not None\n",
    "        \n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed360e2",
   "metadata": {},
   "source": [
    "## Watched filter с помощью redis\n",
    "\n",
    "https://redis-py.readthedocs.io/en/stable/redismodules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca07f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(db=1)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1ddb495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# создадим БД watched_filter, которая будет расчитана на предопределенное число интеракций\n",
    "# и делать в среднем 0.1% (вероятность делится на 100) ложноположительных срабатываний\n",
    "r.bf().reserve('watched_filter', 0.001, n_interactions)\n",
    "\n",
    "for item, user in interactions:\n",
    "    r.bf().add('watched_filter', f'{item}-{user}')\n",
    "    \n",
    "for item, user in interactions:\n",
    "    assert r.bf().exists('watched_filter', f'{item}-{user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f360deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20032"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24beb5b",
   "metadata": {},
   "source": [
    "Для хранения используем в ~ 30 раз меньше памяти\n",
    "\n",
    "Теперь проверим, изменилось ли время работы и сколько ложноположительных срабатываний произошло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b36ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ложноположительных ошибок: 5\n",
      "0.5422 ± 0.4093 ms\n"
     ]
    }
   ],
   "source": [
    "num_errors = 0\n",
    "get_time_elapsed = []\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.bf().exists('watched_filter', f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions and get_result == 0:\n",
    "        raise Exception('У bloom filter не бывает ложноотрицательных срабатываний')\n",
    "    if (item, user) not in interactions and get_result == 1:\n",
    "        num_errors += 1\n",
    "        \n",
    "print(f'Количество ложноположительных ошибок: {num_errors}')\n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
