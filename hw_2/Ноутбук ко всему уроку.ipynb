{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67984e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расскоментируйте код ниже, чтобы установить все зависимости\n",
    "!pip install -q \\\n",
    "    pyarrow==12.0.1 \\\n",
    "    polars==0.18.6 \\\n",
    "    tqdm==4.65.0 \\\n",
    "    scipy==1.10.1 \\\n",
    "    scikit-learn==1.3.0 \\\n",
    "    numpy==1.24.3 \\\n",
    "    qdrant-client==1.3.1 \\\n",
    "    faiss-cpu==1.7.4 \\\n",
    "    redis==4.6.0 \\\n",
    "    implicit==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e95fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "# раскоментируйте код ниже, чтобы скачать данные\n",
    "!wget -q https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -q ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48c874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import redis\n",
    "import faiss\n",
    "import implicit\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from typing import List, Any\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16160e2d",
   "metadata": {},
   "source": [
    "## MovieLens датасет\n",
    "\n",
    "В качестве данных будем использовать датасет с оценками к фильмам Movielens-100k. В нем есть поле ratings, в качестве позитивных событий мы будем считать то, что пользователь поставил оценку > 3 (такое правило принято в статьях, работающих с этим датасетом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b843a01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (55_375, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th><th>timestamp</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>298</td><td>474</td><td>4</td><td>884182806</td></tr><tr><td>253</td><td>465</td><td>5</td><td>891628467</td></tr><tr><td>286</td><td>1014</td><td>5</td><td>879781125</td></tr><tr><td>200</td><td>222</td><td>5</td><td>876042340</td></tr><tr><td>122</td><td>387</td><td>5</td><td>879270459</td></tr><tr><td>291</td><td>1042</td><td>4</td><td>874834944</td></tr><tr><td>119</td><td>392</td><td>4</td><td>886176814</td></tr><tr><td>167</td><td>486</td><td>4</td><td>892738452</td></tr><tr><td>299</td><td>144</td><td>4</td><td>877881320</td></tr><tr><td>308</td><td>1</td><td>4</td><td>887736532</td></tr><tr><td>38</td><td>95</td><td>5</td><td>892430094</td></tr><tr><td>63</td><td>277</td><td>4</td><td>875747401</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>429</td><td>199</td><td>5</td><td>882386006</td></tr><tr><td>897</td><td>369</td><td>4</td><td>879993713</td></tr><tr><td>936</td><td>287</td><td>4</td><td>886832419</td></tr><tr><td>821</td><td>151</td><td>4</td><td>874792889</td></tr><tr><td>113</td><td>975</td><td>5</td><td>875936424</td></tr><tr><td>864</td><td>685</td><td>4</td><td>888891900</td></tr><tr><td>617</td><td>582</td><td>4</td><td>883789294</td></tr><tr><td>421</td><td>498</td><td>4</td><td>892241344</td></tr><tr><td>495</td><td>1091</td><td>4</td><td>888637503</td></tr><tr><td>806</td><td>421</td><td>4</td><td>882388897</td></tr><tr><td>676</td><td>538</td><td>4</td><td>892685437</td></tr><tr><td>716</td><td>204</td><td>5</td><td>879795543</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (55_375, 4)\n",
       "┌─────────┬─────────┬────────┬───────────┐\n",
       "│ user_id ┆ item_id ┆ rating ┆ timestamp │\n",
       "│ ---     ┆ ---     ┆ ---    ┆ ---       │\n",
       "│ i64     ┆ i64     ┆ i64    ┆ i64       │\n",
       "╞═════════╪═════════╪════════╪═══════════╡\n",
       "│ 298     ┆ 474     ┆ 4      ┆ 884182806 │\n",
       "│ 253     ┆ 465     ┆ 5      ┆ 891628467 │\n",
       "│ 286     ┆ 1014    ┆ 5      ┆ 879781125 │\n",
       "│ 200     ┆ 222     ┆ 5      ┆ 876042340 │\n",
       "│ …       ┆ …       ┆ …      ┆ …         │\n",
       "│ 495     ┆ 1091    ┆ 4      ┆ 888637503 │\n",
       "│ 806     ┆ 421     ┆ 4      ┆ 882388897 │\n",
       "│ 676     ┆ 538     ┆ 4      ┆ 892685437 │\n",
       "│ 716     ┆ 204     ┆ 5      ┆ 879795543 │\n",
       "└─────────┴─────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pl.read_csv(\n",
    "    'ml-100k/u.data',\n",
    "    separator='\\t',\n",
    "    has_header=False,\n",
    "    new_columns=['user_id', 'item_id', 'rating', 'timestamp']\n",
    ")\n",
    "# в качестве позитивной реакции возьмем оценки больше 3\n",
    "ratings = ratings.filter(pl.col('rating') > 3)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efaf213-9e72-4ead-9335-7644bb6f9143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>rating</th><th>counts</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>4</td><td>34174</td></tr><tr><td>5</td><td>21201</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────┬────────┐\n",
       "│ rating ┆ counts │\n",
       "│ ---    ┆ ---    │\n",
       "│ i64    ┆ u32    │\n",
       "╞════════╪════════╡\n",
       "│ 4      ┆ 34174  │\n",
       "│ 5      ┆ 21201  │\n",
       "└────────┴────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a939b47-c1eb-437a-b87d-1ca577ca704b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 1447)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['user_id'].n_unique(), ratings['item_id'].n_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77812903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# возьмем последние 5% по времени в качестве отложенной выборки\n",
    "# все что до этого момента, будем использовать для обучения модели\n",
    "ts_threshold = ratings['timestamp'].quantile(0.95)\n",
    "holdout_set = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "ratings = ratings.filter(pl.col('timestamp') < ts_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76842b57-83dc-455c-902c-90fa6881031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(911, 1415)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['user_id'].n_unique(), ratings['item_id'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7f3a9-a4a0-4482-a21e-6451f49f3ac1",
   "metadata": {},
   "source": [
    "не все объекты и пользователи попали в датасет для обучения модели коллаборативной фильтрации. Значит будет проблема холодных пользователей и объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TOP_K = 10\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    random.seed(RANDOM_STATE)\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "def fit_als(ratings: pl.DataFrame, als_params={\"factors\": 64}):\n",
    "    \"\"\"Метод обучает модель ALS и возвращает эмбеддинги пользователей и объектов\n",
    "    Про ALS мы поговорим в следующем уроке, а пока что воспользуемся реализацией из библиотеки implicit\n",
    "\n",
    "    :param ratings: датафрейм с рейтингами\n",
    "    :param als_params: параметры для обучения модели ALS\n",
    "    :return: (user_embeddings, item_embeddings)\n",
    "    \"\"\"\n",
    "    set_seed()\n",
    "\n",
    "    # соберем разреженную матрицу рейтингов\n",
    "    rows = ratings[\"user_id\"].to_numpy()\n",
    "    cols = ratings[\"item_id\"].to_numpy()\n",
    "    values = ratings[\"rating\"].to_numpy() if \"rating\" in ratings else np.ones_like(rows)\n",
    "    user_item_data = sp.csr_matrix((values, (rows, cols)))\n",
    "\n",
    "    # обучим модель ALS\n",
    "    als_params.setdefault(\"random_state\", RANDOM_STATE)\n",
    "    # если есть gpu, используем его для ускорения\n",
    "    als_params.setdefault(\"use_gpu\", implicit.gpu.HAS_CUDA)\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(**als_params)\n",
    "    model.fit(user_item_data)\n",
    "\n",
    "    if als_params['use_gpu']:\n",
    "        return model.user_factors.to_numpy(), model.item_factors.to_numpy()\n",
    "\n",
    "    return model.user_factors, model.item_factors\n",
    "\n",
    "\n",
    "def get_recommendations(user_embs: np.array, item_embs: np.array, k: int = TOP_K):\n",
    "    # строим индекс объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    # строим рекомендации с помощью dot-product расстояния\n",
    "    # с запасом, чтобы после фильтрации просмотренных осталось как минимум TOP_K\n",
    "    return index.search(user_embs, TOP_K * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554afec",
   "metadata": {},
   "source": [
    "## Метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f354b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_hitrate(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    :param y_rel: релевантные объекты\n",
    "    :param y_rec: рекомендованные объекты\n",
    "    :param k: число рекомендации для показа (top-K результаты)\n",
    "    :return: 1, если top-k рекомендации содержат как минимум один релевантный объект\n",
    "    \"\"\"\n",
    "    return int(len(set(y_rec[:k]).intersection(set(y_rel))) > 0)\n",
    "\n",
    "\n",
    "# метод для оценки качества на отложенной выборке\n",
    "# можно сначала посмотреть следующие ячейки, чтобы понять, что тут происходит\n",
    "def evaluate_holdout_set(\n",
    "    train_df: pl.DataFrame, user_embs: np.array, item_embs: np.array, k: int = TOP_K\n",
    "):\n",
    "    # строим индекс эмбеддингов объектов\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    index.add(item_embs)\n",
    "\n",
    "    hitrate_list = []\n",
    "    hitrate_list_by_type = {\"warm\": [], \"cold\": []}\n",
    "\n",
    "    # датафрейм с колонками user_id, train_item_ids, test_item_ids\n",
    "    # нам интересно провалидировать только по тем пользователям, которые есть в отложенной выборке\n",
    "    # поэтому train_item_ids может быть пустым\n",
    "    grouped_user_items = (\n",
    "        holdout_set.groupby(\"user_id\")\n",
    "        .agg(pl.col(\"item_id\").alias(\"test_item_ids\"))\n",
    "        .join(\n",
    "            train_df.groupby(\"user_id\").agg(pl.col(\"item_id\").alias(\"train_item_ids\")),\n",
    "            \"user_id\",\n",
    "            \"left\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # предподсчитаем рекомендации по эмбеддингам пользователей и объектов (только для warm пользователей)\n",
    "    _, recs = get_recommendations(user_embs, item_embs)\n",
    "\n",
    "    for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "        if train_ids:\n",
    "            # если есть история для пользователя, то используем предподсчитанные рекомендации\n",
    "            user_history = train_ids\n",
    "\n",
    "            y_rel = test_ids\n",
    "            y_rec = [\n",
    "                item_id for item_id in recs[user_id] if item_id not in user_history\n",
    "            ]\n",
    "            hitrate_list_by_type[\"warm\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "        else:\n",
    "            # если нет истории пользователя, то используем сумму эмбеддингов объектов\n",
    "            user_emb = np.zeros(item_embs.shape[1])\n",
    "            user_history = set()\n",
    "            h_r = []\n",
    "            for i, item_ind in enumerate(test_ids[:-1]):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                user_history.add(item_ind)\n",
    "                \n",
    "                # хотим порекомендовать следующий объект\n",
    "                y_rel = [test_ids[i + 1]]\n",
    "                y_rec = [\n",
    "                    item_id\n",
    "                    for item_id in index.search(user_emb[np.newaxis, :], k + 1)[1][0]\n",
    "                    if item_id not in user_history\n",
    "                ]\n",
    "                hitrate_list_by_type[\"cold\"].append(user_hitrate(y_rel, y_rec, k))\n",
    "            \n",
    "    all_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"] + hitrate_list_by_type[\"cold\"])\n",
    "    warm_users_hitrate = np.mean(hitrate_list_by_type[\"warm\"]) if hitrate_list_by_type[\"warm\"] else 1.0\n",
    "    cold_users_hitrate = np.mean(hitrate_list_by_type[\"cold\"]) if hitrate_list_by_type[\"cold\"] else 1.0\n",
    "    return {\n",
    "        \"all\": all_users_hitrate,\n",
    "        \"warm\": warm_users_hitrate,\n",
    "        \"cold\": cold_users_hitrate,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 3) == 1\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 2], 2) == 0\n",
    "assert user_hitrate([1, 2, 3], [4, 5, 6], 10) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e3c7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Случайная вадидация\n",
    "\n",
    "Можно сказать, что в валидацию попадает какой-то процент взаимодействий, а в тренировочную выборку все остальное. С точки зрения реализации самый простой способ, однако совсем никак не контролирует дата-лики, когда информация из будущего оказывается в прошлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    ratings,\n",
    "    # будем сэмплировать так, чтобы пользователи встречались с той же вероятностью\n",
    "    stratify=ratings['user_id'],\n",
    "    test_size=TEST_SIZE,\n",
    "    # зафиксируем генератор случайных чисел для воспроизводимости результатов\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ceacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a51848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (904, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>670</td><td>[417, 603, 174]</td><td>[705, 245, … 195]</td></tr><tr><td>430</td><td>[181, 258, … 1375]</td><td>[303, 527, … 674]</td></tr><tr><td>800</td><td>[121, 50]</td><td>[275, 300, … 222]</td></tr><tr><td>654</td><td>[742, 111, … 462]</td><td>[1035, 98, … 28]</td></tr><tr><td>346</td><td>[182, 520, … 12]</td><td>[117, 203, … 195]</td></tr><tr><td>124</td><td>[154]</td><td>[144, 226, … 7]</td></tr><tr><td>310</td><td>[845]</td><td>[304, 24, … 50]</td></tr><tr><td>758</td><td>[896, 640, … 285]</td><td>[650, 628, … 316]</td></tr><tr><td>240</td><td>[313]</td><td>[245, 289, … 242]</td></tr><tr><td>102</td><td>[89, 510]</td><td>[227, 98, … 95]</td></tr><tr><td>262</td><td>[1147, 650, … 65]</td><td>[923, 22, … 11]</td></tr><tr><td>212</td><td>[382, 317]</td><td>[246, 528, … 268]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>203</td><td>[151, 815]</td><td>[288, 326, … 283]</td></tr><tr><td>463</td><td>[253, 283, … 269]</td><td>[301, 813, … 221]</td></tr><tr><td>79</td><td>[283, 262, … 268]</td><td>[286, 50, … 258]</td></tr><tr><td>93</td><td>[275]</td><td>[477, 845, … 222]</td></tr><tr><td>537</td><td>[699, 515, … 238]</td><td>[1103, 882, … 131]</td></tr><tr><td>209</td><td>[293]</td><td>[1, 181, … 285]</td></tr><tr><td>491</td><td>[100, 513]</td><td>[129, 657, … 236]</td></tr><tr><td>327</td><td>[475, 523, … 856]</td><td>[582, 288, … 98]</td></tr><tr><td>781</td><td>[179, 181, 474]</td><td>[302, 87, … 204]</td></tr><tr><td>749</td><td>[15, 11, … 209]</td><td>[837, 977, … 521]</td></tr><tr><td>539</td><td>[69, 269, … 603]</td><td>[131, 285, … 170]</td></tr><tr><td>585</td><td>[1121, 20, … 639]</td><td>[509, 1158, … 707]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (904, 3)\n",
       "┌─────────┬────────────────────┬────────────────────┐\n",
       "│ user_id ┆ test_item_ids      ┆ train_item_ids     │\n",
       "│ ---     ┆ ---                ┆ ---                │\n",
       "│ i64     ┆ list[i64]          ┆ list[i64]          │\n",
       "╞═════════╪════════════════════╪════════════════════╡\n",
       "│ 670     ┆ [417, 603, 174]    ┆ [705, 245, … 195]  │\n",
       "│ 430     ┆ [181, 258, … 1375] ┆ [303, 527, … 674]  │\n",
       "│ 800     ┆ [121, 50]          ┆ [275, 300, … 222]  │\n",
       "│ 654     ┆ [742, 111, … 462]  ┆ [1035, 98, … 28]   │\n",
       "│ …       ┆ …                  ┆ …                  │\n",
       "│ 781     ┆ [179, 181, 474]    ┆ [302, 87, … 204]   │\n",
       "│ 749     ┆ [15, 11, … 209]    ┆ [837, 977, … 521]  │\n",
       "│ 539     ┆ [69, 269, … 603]   ┆ [131, 285, … 170]  │\n",
       "│ 585     ┆ [1121, 20, … 639]  ┆ [509, 1158, … 707] │\n",
       "└─────────┴────────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгруппируем в список индексов объекты из тренировочной выборки и валидационной\n",
    "train_user_items = train_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"train_item_ids\")\n",
    ")\n",
    "test_user_items = test_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"test_item_ids\")\n",
    ")\n",
    "# объединим все в одну табличку, при этом важно оставить всех тех\n",
    "# пользователей, которые есть в валидационной выборке\n",
    "grouped_user_items = test_user_items.join(train_user_items, \"user_id\", \"left\")\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 1.0\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    # строим рекомендации из тех объектов, которые уже не были в тренировочной выборке\n",
    "    y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de03b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.06108597285067873,\n",
       " 'warm': 0.21739130434782608,\n",
       " 'cold': 0.05473808122424956}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca18a0d",
   "metadata": {},
   "source": [
    "На валидации получили идеальную метрику hitrate, однако на отложенной выборке самый худший результат по сравнению со следующими методами валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c0b1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Валидация по пользователям\n",
    "\n",
    "Здесь мы делаем разделение данных уже по полю user_id, то есть какие-то пользователи попадут только в тестовую выборку и с точки зрения алгоритма будут холодными (cold) пользователями\n",
    "\n",
    "Для того, чтобы построить рекомендации для таких пользователей, будем использовать эмбеддинги объектов в реальном времени. То есть если для валидации у нас есть список объектов [item_1, item_2, item_3, ...], то для первого объекта ничего не рекомендуем (или еще лучше рекомендовать популярные объекты). В момент рекомендации второго объекта у нас есть история для пользователя: [item_1], тогда эмбединг пользователя равен эмбеддингу item_1. Для следующего объекта эмбеддинг будет равен сумме эмбеддингов item_1 и item_2 и так далее.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем генератор случайных чисел для воспроизводимости\n",
    "np.random.seed(RANDOM_STATE)  \n",
    "\n",
    "# выберем среди всех пользователей тех, кто будет в тренировочной выборке, а кто в тестовой\n",
    "unique_users = ratings[\"user_id\"].unique().to_list()\n",
    "test_users = set(\n",
    "    np.random.choice(unique_users, int(len(unique_users) * TEST_SIZE), replace=False)\n",
    ")\n",
    "train_users = set(unique_users).difference(test_users)\n",
    "\n",
    "train_df = ratings.filter(pl.col(\"user_id\").is_in(train_users))\n",
    "test_df = ratings.filter(pl.col(\"user_id\").is_in(test_users))\n",
    "\n",
    "# sanity check\n",
    "assert set(train_df[\"user_id\"].unique().to_list()) == train_users\n",
    "assert set(test_df[\"user_id\"].unique().to_list()) == test_users\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b344c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe1c31-d4f4-4775-aabd-0baf47b45d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (91, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>702</td><td>[228, 313, … 380]</td><td>null</td></tr><tr><td>780</td><td>[662, 491, … 50]</td><td>null</td></tr><tr><td>884</td><td>[116, 70, … 463]</td><td>null</td></tr><tr><td>538</td><td>[963, 202, … 89]</td><td>null</td></tr><tr><td>472</td><td>[401, 193, … 96]</td><td>null</td></tr><tr><td>524</td><td>[205, 89, … 481]</td><td>null</td></tr><tr><td>92</td><td>[172, 168, … 65]</td><td>null</td></tr><tr><td>34</td><td>[312, 242, … 991]</td><td>null</td></tr><tr><td>516</td><td>[191, 628, … 582]</td><td>null</td></tr><tr><td>76</td><td>[61, 175, … 96]</td><td>null</td></tr><tr><td>396</td><td>[841, 291, … 323]</td><td>null</td></tr><tr><td>556</td><td>[327, 496, … 321]</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>483</td><td>[181, 275, … 676]</td><td>null</td></tr><tr><td>743</td><td>[224, 100, … 242]</td><td>null</td></tr><tr><td>303</td><td>[919, 69, … 88]</td><td>null</td></tr><tr><td>869</td><td>[412, 310, … 249]</td><td>null</td></tr><tr><td>923</td><td>[333, 237, … 411]</td><td>null</td></tr><tr><td>69</td><td>[256, 268, … 79]</td><td>null</td></tr><tr><td>823</td><td>[211, 81, … 134]</td><td>null</td></tr><tr><td>731</td><td>[197, 192, … 496]</td><td>null</td></tr><tr><td>783</td><td>[346, 876, … 895]</td><td>null</td></tr><tr><td>559</td><td>[902, 188, … 652]</td><td>null</td></tr><tr><td>681</td><td>[898, 539, … 292]</td><td>null</td></tr><tr><td>455</td><td>[135, 293, … 164]</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (91, 3)\n",
       "┌─────────┬───────────────────┬────────────────┐\n",
       "│ user_id ┆ test_item_ids     ┆ train_item_ids │\n",
       "│ ---     ┆ ---               ┆ ---            │\n",
       "│ i64     ┆ list[i64]         ┆ list[i64]      │\n",
       "╞═════════╪═══════════════════╪════════════════╡\n",
       "│ 702     ┆ [228, 313, … 380] ┆ null           │\n",
       "│ 780     ┆ [662, 491, … 50]  ┆ null           │\n",
       "│ 884     ┆ [116, 70, … 463]  ┆ null           │\n",
       "│ 538     ┆ [963, 202, … 89]  ┆ null           │\n",
       "│ …       ┆ …                 ┆ …              │\n",
       "│ 783     ┆ [346, 876, … 895] ┆ null           │\n",
       "│ 559     ┆ [902, 188, … 652] ┆ null           │\n",
       "│ 681     ┆ [898, 539, … 292] ┆ null           │\n",
       "│ 455     ┆ [135, 293, … 164] ┆ null           │\n",
       "└─────────┴───────────────────┴────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сгруппируем в список индексов объекты из тренировочной выборки и валидационной\n",
    "train_user_items = train_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"train_item_ids\")\n",
    ")\n",
    "test_user_items = test_df.groupby(\"user_id\").agg(\n",
    "    pl.col(\"item_id\").alias(\"test_item_ids\")\n",
    ")\n",
    "# объединим все в одну табличку, при этом важно оставить всех тех\n",
    "# пользователей, которые есть в валидационной выборке\n",
    "grouped_user_items = test_user_items.join(train_user_items, \"user_id\", \"left\")\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72030097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.11200508151598561\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "hitrate_list = []\n",
    "for _, user_session, _ in grouped_user_items.rows():\n",
    "    user_emb = np.zeros(item_embs.shape[1])\n",
    "    user_history = set()\n",
    "    # эмбеддинг пользователя - сумма эмбеддингов позитивных объектов\n",
    "    # пройдемся по каждому объекту и постараемся предсказать следующие в сессии\n",
    "    for i, item_ind in enumerate(user_session[:-1]):\n",
    "        user_emb += item_embs[item_ind]\n",
    "        user_history.add(item_ind)\n",
    "        \n",
    "        y_rel = [user_session[i + 1]]\n",
    "        y_rec = [\n",
    "            item_id \n",
    "            for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "            if item_id not in user_history\n",
    "        ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd292f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.06195175438596491,\n",
       " 'warm': 0.27419354838709675,\n",
       " 'cold': 0.05448354143019296}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a71c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Валидация по времени\n",
    "\n",
    "Такая валидация дублирует реально поведение системы, когда у нас есть данные только из прошлого и мы хотим порекомендовать для будущего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c38de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_threshold = ratings['timestamp'].quantile(1 - TEST_SIZE)\n",
    "train_df = ratings.filter(pl.col('timestamp') < ts_threshold)\n",
    "test_df = ratings.filter(pl.col('timestamp') >= ts_threshold)\n",
    "\n",
    "assert len(train_df) + len(test_df) == len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3644c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (126, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>test_item_ids</th><th>train_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>934</td><td>[25, 197, … 419]</td><td>[50, 297, … 462]</td></tr><tr><td>190</td><td>[405]</td><td>[117, 302, … 288]</td></tr><tr><td>856</td><td>[258, 750, … 272]</td><td>null</td></tr><tr><td>574</td><td>[300, 258, … 754]</td><td>null</td></tr><tr><td>26</td><td>[125, 15, … 288]</td><td>null</td></tr><tr><td>642</td><td>[845, 993, 245]</td><td>[1039, 38, … 73]</td></tr><tr><td>704</td><td>[205, 354, … 134]</td><td>null</td></tr><tr><td>816</td><td>[309, 343, … 690]</td><td>null</td></tr><tr><td>720</td><td>[258, 304, … 242]</td><td>null</td></tr><tr><td>334</td><td>[282, 603, … 47]</td><td>null</td></tr><tr><td>636</td><td>[222, 596, … 235]</td><td>null</td></tr><tr><td>938</td><td>[864, 313, … 993]</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>489</td><td>[1293, 292, … 879]</td><td>null</td></tr><tr><td>659</td><td>[66, 507, … 657]</td><td>[272, 153, … 216]</td></tr><tr><td>547</td><td>[328, 316, … 751]</td><td>null</td></tr><tr><td>423</td><td>[744, 237, … 508]</td><td>null</td></tr><tr><td>649</td><td>[1, 1016, … 127]</td><td>null</td></tr><tr><td>119</td><td>[451, 995]</td><td>[392, 1153, … 257]</td></tr><tr><td>639</td><td>[242, 488, … 514]</td><td>null</td></tr><tr><td>753</td><td>[79, 898, … 193]</td><td>null</td></tr><tr><td>223</td><td>[274, 969, … 546]</td><td>null</td></tr><tr><td>903</td><td>[182, 276, … 81]</td><td>[100, 318, … 50]</td></tr><tr><td>741</td><td>[435, 70, … 945]</td><td>[69, 651, … 724]</td></tr><tr><td>335</td><td>[245, 269, … 340]</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (126, 3)\n",
       "┌─────────┬───────────────────┬───────────────────┐\n",
       "│ user_id ┆ test_item_ids     ┆ train_item_ids    │\n",
       "│ ---     ┆ ---               ┆ ---               │\n",
       "│ i64     ┆ list[i64]         ┆ list[i64]         │\n",
       "╞═════════╪═══════════════════╪═══════════════════╡\n",
       "│ 934     ┆ [25, 197, … 419]  ┆ [50, 297, … 462]  │\n",
       "│ 190     ┆ [405]             ┆ [117, 302, … 288] │\n",
       "│ 856     ┆ [258, 750, … 272] ┆ null              │\n",
       "│ 574     ┆ [300, 258, … 754] ┆ null              │\n",
       "│ …       ┆ …                 ┆ …                 │\n",
       "│ 223     ┆ [274, 969, … 546] ┆ null              │\n",
       "│ 903     ┆ [182, 276, … 81]  ┆ [100, 318, … 50]  │\n",
       "│ 741     ┆ [435, 70, … 945]  ┆ [69, 651, … 724]  │\n",
       "│ 335     ┆ [245, 269, … 340] ┆ null              │\n",
       "└─────────┴───────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_items = train_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('train_item_ids')\n",
    ")\n",
    "test_user_items = test_df.groupby('user_id').agg(\n",
    "    pl.col('item_id').alias('test_item_ids')\n",
    ")\n",
    "grouped_user_items = test_user_items.join(train_user_items, 'user_id', 'left')\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa80a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.1154877294287482\n"
     ]
    }
   ],
   "source": [
    "# строим индекс объектов\n",
    "index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "index.add(item_embs)\n",
    "    \n",
    "for user_id, test_ids, train_ids in grouped_user_items.rows():\n",
    "    if train_ids:\n",
    "        # используем инференс модели с помощью эмбеддинга пользователя\n",
    "        user_history = train_ids\n",
    "        \n",
    "        y_rel = test_ids\n",
    "        y_rec = [item_id for item_id in recs[user_id] if item_id not in user_history]\n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "    else:\n",
    "        # используем итеративный эмбеддинг по объектам\n",
    "        user_emb = np.zeros(item_embs.shape[1])\n",
    "        user_history = set()\n",
    "        for i, item_ind in enumerate(test_ids[:-1]):\n",
    "            if item_ind < len(item_embs):\n",
    "                user_emb += item_embs[item_ind]\n",
    "                \n",
    "            user_history.add(item_ind)    \n",
    "            y_rel = [test_ids[i + 1]]\n",
    "            y_rec = [\n",
    "                item_id \n",
    "                for item_id in index.search(user_emb[np.newaxis, :], TOP_K * 3)[1][0]\n",
    "                if item_id not in user_history\n",
    "            ]\n",
    "    \n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec, TOP_K))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.060228452751817235,\n",
       " 'warm': 0.20689655172413793,\n",
       " 'cold': 0.055674518201284794}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba7267",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Валидация по событиям\n",
    "\n",
    "В такой валидации мы рассматриваем для пользователя все взаимодействия, отсортированные по времени и оставляем последние N взаимодействия в качестве валидации, а все что раньше – для тренировки. У этого способа есть такая же проблема с тем, что при обучении могут сказываться дата-лики, однако в этом случае мы учитываем как холодных, так и теплых пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b23fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (911, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>train_item_ids</th><th>test_item_ids</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>936</td><td>[313, 272, … 1129]</td><td>[255]</td></tr><tr><td>128</td><td>[319, 300, … 684]</td><td>[88]</td></tr><tr><td>736</td><td>[246, 296, … 127]</td><td>[253]</td></tr><tr><td>512</td><td>[302, 1238, … 23]</td><td>[1]</td></tr><tr><td>770</td><td>[303, 258, … 326]</td><td>[937]</td></tr><tr><td>116</td><td>[258, 289, … 313]</td><td>[900]</td></tr><tr><td>378</td><td>[286, 304, … 269]</td><td>[703]</td></tr><tr><td>276</td><td>[258, 300, … 14]</td><td>[737]</td></tr><tr><td>46</td><td>[690, 313, … 50]</td><td>[125]</td></tr><tr><td>248</td><td>[343, 324, … 249]</td><td>[405]</td></tr><tr><td>494</td><td>[286, 294, … 15]</td><td>[126]</td></tr><tr><td>782</td><td>[313, 315, … 1391]</td><td>[1662]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>49</td><td>[302, 346, … 386]</td><td>[518]</td></tr><tr><td>343</td><td>[303, 269, … 81]</td><td>[510]</td></tr><tr><td>889</td><td>[302, 269, … 1113]</td><td>[217]</td></tr><tr><td>833</td><td>[240, 127, … 1143]</td><td>[344]</td></tr><tr><td>633</td><td>[300, 328, … 423]</td><td>[234]</td></tr><tr><td>857</td><td>[898, 258, … 116]</td><td>[275]</td></tr><tr><td>201</td><td>[313, 242, … 233]</td><td>[227]</td></tr><tr><td>763</td><td>[286, 98, … 625]</td><td>[1039]</td></tr><tr><td>681</td><td>[286, 750, … 294]</td><td>[289]</td></tr><tr><td>593</td><td>[181, 100, … 223]</td><td>[1016]</td></tr><tr><td>199</td><td>[258, 269, … 473]</td><td>[14]</td></tr><tr><td>871</td><td>[347, 271, … 202]</td><td>[781]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (911, 3)\n",
       "┌─────────┬────────────────────┬───────────────┐\n",
       "│ user_id ┆ train_item_ids     ┆ test_item_ids │\n",
       "│ ---     ┆ ---                ┆ ---           │\n",
       "│ i64     ┆ list[i64]          ┆ list[i64]     │\n",
       "╞═════════╪════════════════════╪═══════════════╡\n",
       "│ 936     ┆ [313, 272, … 1129] ┆ [255]         │\n",
       "│ 128     ┆ [319, 300, … 684]  ┆ [88]          │\n",
       "│ 736     ┆ [246, 296, … 127]  ┆ [253]         │\n",
       "│ 512     ┆ [302, 1238, … 23]  ┆ [1]           │\n",
       "│ …       ┆ …                  ┆ …             │\n",
       "│ 681     ┆ [286, 750, … 294]  ┆ [289]         │\n",
       "│ 593     ┆ [181, 100, … 223]  ┆ [1016]        │\n",
       "│ 199     ┆ [258, 269, … 473]  ┆ [14]          │\n",
       "│ 871     ┆ [347, 271, … 202]  ┆ [781]         │\n",
       "└─────────┴────────────────────┴───────────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_user_items = (\n",
    "    ratings\n",
    "    .sort('timestamp')\n",
    "    .groupby('user_id')\n",
    "    .agg([\n",
    "        pl.col('item_id').apply(lambda x: x[:-1]).alias('train_item_ids'),\n",
    "        pl.col('item_id').apply(lambda x: [x[-1]]).alias('test_item_ids')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# sanity check\n",
    "assert len(\n",
    "    grouped_user_items\n",
    "    .filter(pl.col('test_item_ids').apply(lambda x: len(x) == 0))\n",
    ") == 0\n",
    "\n",
    "grouped_user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4b783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = (\n",
    "    grouped_user_items\n",
    "    .select('user_id', 'train_item_ids')\n",
    "    .explode('train_item_ids')\n",
    "    .rename({'train_item_ids': 'item_id'})\n",
    ")\n",
    "\n",
    "user_embs, item_embs = fit_als(train_df)\n",
    "probs, recs = get_recommendations(user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e96425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hitrate@10 = 0.09330406147091108\n"
     ]
    }
   ],
   "source": [
    "hitrate_list = []\n",
    "for user_id, user_history, y_rel in grouped_user_items.rows():\n",
    "    y_rec = [\n",
    "        item_id\n",
    "        for item_id in recs[user_id]\n",
    "        if item_id not in user_history\n",
    "    ]\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "print(f'Hitrate@{TOP_K} = {np.mean(hitrate_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2794ee74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 0.07352941176470588,\n",
       " 'warm': 0.2318840579710145,\n",
       " 'cold': 0.06709829311359623}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_holdout_set(train_df, user_embs, item_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcf2e9",
   "metadata": {},
   "source": [
    "## Approximate KNN с помощью Qdrant\n",
    "\n",
    "В отдельном процессе нужно запустить серверную часть [qdrant](https://qdrant.tech/) следующей командой:\n",
    "\n",
    "`docker run -p 6333:6333 qdrant/qdrant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a6394cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = QdrantClient(\"localhost\", port=6333)\n",
    "client = QdrantClient(\"37.27.29.69\", port=6333)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"item_embs\",\n",
    "    # задаем размерность векторов и метрику дистанции\n",
    "    vectors_config=VectorParams(size=item_embs.shape[1], distance=Distance.DOT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84ae462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation_info = client.upsert(\n",
    "    collection_name=\"item_embs\",\n",
    "    wait=True,\n",
    "    points=[\n",
    "        PointStruct(id=(item_id + 1), vector=item_emb.tolist())\n",
    "        for item_id, item_emb in enumerate(item_embs)\n",
    "    ]\n",
    ")\n",
    "operation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d4c9326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=223, version=0, score=0.33593744, payload={}, vector=None),\n",
       " ScoredPoint(id=229, version=0, score=0.3137651, payload={}, vector=None),\n",
       " ScoredPoint(id=203, version=0, score=0.30500668, payload={}, vector=None),\n",
       " ScoredPoint(id=228, version=0, score=0.28869912, payload={}, vector=None),\n",
       " ScoredPoint(id=406, version=0, score=0.2651918, payload={}, vector=None),\n",
       " ScoredPoint(id=231, version=0, score=0.23766066, payload={}, vector=None),\n",
       " ScoredPoint(id=230, version=0, score=0.18517748, payload={}, vector=None),\n",
       " ScoredPoint(id=197, version=0, score=0.18087247, payload={}, vector=None),\n",
       " ScoredPoint(id=381, version=0, score=0.17907017, payload={}, vector=None),\n",
       " ScoredPoint(id=152, version=0, score=0.163593, payload={}, vector=None)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 183\n",
    "search_result = client.search(\n",
    "    collection_name=\"item_embs\",\n",
    "    query_vector=user_embs[user_id].tolist(),\n",
    "    limit=TOP_K\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5af269c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rel = holdout_set.filter(pl.col('user_id') == user_id)['item_id'].to_list()\n",
    "y_rec = [s.id for s in search_result]\n",
    "user_hitrate(y_rel, y_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cc743",
   "metadata": {},
   "source": [
    "## watched filter с разреженной матрицей\n",
    "\n",
    "Для работы с redis нужно запустить docker контейнер следующей командой:\n",
    "\n",
    "`docker run --rm -p 6379:6379 redis/redis-stack-server:latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7887ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "n_interactions = 10_000\n",
    "n_users = 10_000\n",
    "n_items = 1_000_000\n",
    "\n",
    "# wanna generate sparse matrix\n",
    "assert n_interactions <= n_users * n_items / 100\n",
    "\n",
    "interactions = set()\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    while True:\n",
    "        user = np.random.choice(n_users)\n",
    "        item = np.random.choice(n_items)\n",
    "\n",
    "        if (item, user) not in interactions:\n",
    "            interactions.add((item, user))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03b2ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='37.27.29.69', db=0)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22d321b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, user in interactions:\n",
    "    r.set(f'{item}-{user}', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540456"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdd76a",
   "metadata": {},
   "source": [
    "Использовали ~500Кб памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e39a79cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9883 ± 0.2673 ms\n"
     ]
    }
   ],
   "source": [
    "for item, user in interactions:\n",
    "    assert r.get(f'{item}-{user}') is not None\n",
    "    \n",
    "get_time_elapsed = []\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.get(f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions:\n",
    "        assert get_result is not None\n",
    "        \n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed360e2",
   "metadata": {},
   "source": [
    "## Watched filter с помощью redis\n",
    "\n",
    "https://redis-py.readthedocs.io/en/stable/redismodules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca07f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='37.27.29.69', db=1)\n",
    "used_memory_before = r.info('memory')['used_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1ddb495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# создадим БД watched_filter, которая будет расчитана на предопределенное число интеракций\n",
    "# и делать в среднем 0.1% (вероятность делится на 100) ложноположительных срабатываний\n",
    "r.bf().reserve('watched_filter', 0.001, n_interactions)\n",
    "\n",
    "for item, user in interactions:\n",
    "    r.bf().add('watched_filter', f'{item}-{user}')\n",
    "    \n",
    "for item, user in interactions:\n",
    "    assert r.bf().exists('watched_filter', f'{item}-{user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f360deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79960"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.info('memory')['used_memory'] - used_memory_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24beb5b",
   "metadata": {},
   "source": [
    "Для хранения используем в ~ 30 раз меньше памяти\n",
    "\n",
    "Теперь проверим, изменилось ли время работы и сколько ложноположительных срабатываний произошло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ложноположительных ошибок: 5\n",
      "16.8375 ± 8.8341 ms\n"
     ]
    }
   ],
   "source": [
    "num_errors = 0\n",
    "get_time_elapsed = []\n",
    "\n",
    "for _ in range(n_interactions):\n",
    "    user = np.random.choice(n_users)\n",
    "    item = np.random.choice(n_items)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    get_result = r.bf().exists('watched_filter', f'{item}-{user}')\n",
    "    get_time_elapsed.append((time.time() - t_start) * 1_000)\n",
    "    \n",
    "    if (item, user) in interactions and get_result == 0:\n",
    "        raise Exception('У bloom filter не бывает ложноотрицательных срабатываний')\n",
    "    if (item, user) not in interactions and get_result == 1:\n",
    "        num_errors += 1\n",
    "        \n",
    "print(f'Количество ложноположительных ошибок: {num_errors}')\n",
    "print(f'{np.mean(get_time_elapsed):.4f} ± {np.std(get_time_elapsed):.4f} ms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
